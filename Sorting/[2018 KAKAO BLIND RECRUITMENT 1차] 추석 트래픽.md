# [2018 KAKAO BLIND RECRUITMENT 1차] 추석 트래픽
## 문제
### 문제 설명
([원본 문제](https://programmers.co.kr/learn/courses/30/lessons/17676)의 내용을 복사한 것입니다.)

### 추석 트래픽

이번 추석에도 시스템 장애가 없는 명절을 보내고 싶은 어피치는 서버를 증설해야 할지 고민이다. 
장애 대비용 서버 증설 여부를 결정하기 위해 작년 추석 기간인 9월 15일 로그 데이터를 분석한 후 초당 최대 처리량을 계산해보기로 했다. 
<b>초당 최대 처리량</b>은 요청의 응답 완료 여부에 관계없이 임의 시간부터 1초(=1,000밀리초)간 처리하는 요청의 최대 개수를 의미한다.

### 입력 형식
* `solution` 함수에 전달되는 `lines` 배열은 <b>N</b>(1 ≦ <b>N</b> ≦ 2,000)개의 로그 문자열로 되어 있으며, 각 로그 문자열마다 요청에 대한 응답완료시간 <b>S</b>와 처리시간 <b>T</b>가 공백으로 구분되어 있다.
* 응답완료시간 S는 작년 추석인 2016년 9월 15일만 포함하여 고정 길이 `2016-09-15 hh:mm:ss.sss` 형식으로 되어 있다.
* 처리시간 <b>T</b>는 `0.1s`, `0.312s`, `2s` 와 같이 최대 소수점 셋째 자리까지 기록하며 뒤에는 초 단위를 의미하는 `s`로 끝난다.
* 예를 들어, 로그 문자열 `2016-09-15 03:10:33.020 0.011s`은 "2016년 9월 15일 오전 3시 10분 <b>33.010초</b>"부터 "2016년 9월 15일 오전 3시 10분 <b>33.020초</b>"까지 "<b>0.011초</b>" 동안 처리된 요청을 의미한다. <b>(처리시간은 시작시간과 끝시간을 포함)</b>
* 서버에는 타임아웃이 3초로 적용되어 있기 때문에 처리시간은 <b>0.001 ≦ T ≦ 3.000</b>이다.
* `lines` 배열은 응답완료시간 <b>S</b>를 기준으로 오름차순 정렬되어 있다.

### 출력 형식
* `solution` 함수에서는 로그 데이터 `lines` 배열에 대해 <b>초당 최대 처리량</b>을 리턴한다.

### 입출력 예제
**예제1**

* 입력: [  
"2016-09-15 01:00:04.001 2.0s",  
"2016-09-15 01:00:07.000 2s"  
]

* 출력: 1

**예제2**

* 입력: [  
"2016-09-15 01:00:04.002 2.0s",  
"2016-09-15 01:00:07.000 2s"  
]

* 출력: 2

* 설명: 처리시간은 시작시간과 끝시간을 <b>포함</b>하므로  
첫 번째 로그는 `01:00:02.003 ~ 01:00:04.002`에서 2초 동안 처리되었으며,  
두 번째 로그는 `01:00:05.001 ~ 01:00:07.000`에서 2초 동안 처리된다.  
따라서, 첫 번째 로그가 끝나는 시점과 두 번째 로그가 시작하는 시점의 구간인 `01:00:04.002 ~ 01:00:05.001` 1초 동안 최대 2개가 된다.

**예제3**

* 입력: [  
"2016-09-15 20:59:57.421 0.351s",  
"2016-09-15 20:59:58.233 1.181s",  
"2016-09-15 20:59:58.299 0.8s",  
"2016-09-15 20:59:58.688 1.041s",  
"2016-09-15 20:59:59.591 1.412s",  
"2016-09-15 21:00:00.464 1.466s",  
"2016-09-15 21:00:00.741 1.581s",  
"2016-09-15 21:00:00.748 2.31s",  
"2016-09-15 21:00:00.966 0.381s",  
"2016-09-15 21:00:02.066 2.62s"  
]

* 출력: 7

* 설명: 아래 타임라인 그림에서 빨간색으로 표시된 1초 각 구간의 처리량을 구해보면 `(1)`은 4개, `(2)`는 7개, `(3)`는 2개임을 알 수 있다. 따라서 <b>초당 최대 처리량</b>은 7이 되며, 동일한 최대 처리량을 갖는 1초 구간은 여러 개 존재할 수 있으므로 이 문제에서는 구간이 아닌 개수만 출력한다.

![예시](https://user-images.githubusercontent.com/77680436/117565666-639e7980-b0ed-11eb-9fdd-95949797489f.png)

### 예제에 대한 설명
* 입출력 예제 1의 경우, 첫 번째에는 A 블록 6개가 지워지고, 두 번째에는 B 블록 4개와 C 블록 4개가 지워져, 모두 14개의 블록이 지워진다.
* 입출력 예제 2는 본문 설명에 있는 그림을 옮긴 것이다. 11개와 4개의 블록이 차례로 지워지며, 모두 15개의 블록이 지워진다.

## 제출답안
```python
from datetime import datetime, timedelta
def solution(lines):
    time = []

    for i in range(len(lines)):
        end = datetime.fromisoformat(lines[i][:23]) # 끝나는 시간을 datetime 객체로 저장
        diff = timedelta(seconds=float(lines[i][24:-1])-0.001) # 끝나는 시간과 시작 시간의 차이(0.001을 뺀 것은 처리시간은 시작시간과 끝시간을 포함하므로)
        start = end - diff # 시작 시간을 구해서 datetime 객체로 저장
        time += [(start, i), (end+timedelta(seconds=1), i)] # 전체 타임 리스트에 로그를 나타내는 인덱스와 함께 시작 시간, 끝 시간+1초를 넣음
    time.sort() # 전체 타임 리스트를 정렬

    maxVal = 0
    traffic = set() # 현재 시간에 처리 중인 로그
    for t in time:
        if t[1] in traffic: traffic.remove(t[1]) # (끝 시간 + 1초, 로그 인덱스)를 만났을 때
        else: traffic.add(t[1]) # (시작 시간, 로그 인덱스)를 만났을 때
        if len(traffic) > maxVal: maxVal = len(traffic) # 현재 처리 중인 로그가 가장 많다면 정답 갱신

    return maxVal
```
### 설명
본 문제의 경우 시간에 따라 겹치는 로그의 개수를 세는 문제이다.

본 풀이에서 사용한 방법이 이미 알려진 방법인지는 잘 모르겠으나, 개인적으로 이와 같이 겹치는 것을 판단하는 문제에서 주로 사용하는 방법이다.

사용한 알고리즘은 다음과 같다.
```
1. 모든 로그의 이벤트 시간이 담길 리스트를 만든다.
2. 로그의 시작 시간과 끝 시간을 구하고, 이를 1번의 리스트에 로그를 의미하는 아이디(인덱스)와 함께 각각을 넣는다.
3. 모든 로그에 대해 1번과 2번을 수행하였다면 해당 리스트를 정렬한다.
4. 이벤트 시간이 담긴 리스트를 오름차순으로 순회하면서 겹치는 여부를 판단한다.  
  4-1. 현재 처리 중인 로그가 담길 집합을 만든다. (집합인 이유는 파이썬에서 삽입, 삭제, 존재 여부 조회가 O(1) 이므로)  
  4-2. 리스트에서 하나씩 가져온다.  
  4-3. 가져온 값의 로그 아이디가 4-1번의 집합 안에 없다면 시작 시간을 의미하므로 집합에 추가한다.  
  4-4. 가져온 값의 로그 아이디가 4-1번의 집합 안에 있다면 끝나는 시간을 의미하므로 집합에서 제거한다.  
  4-5. 리스트의 4-2 ~ 4-4의 매 이벤트를 처리할 때마다 집합의 개수(처리 중인 로그 수)를 이용해 답을 갱신한다.
```

알고리즘만 읽어보면 무슨 소리인지 잘 이해가 가지 않을 수 있다.  
예를 들어 예제 2번의 `["2016-09-15 01:00:04.002 2.0s", "2016-09-15 01:00:07.000 2s"]`를 살펴보자.

1번 로그는 끝나는 시간이 "01:00:04.002", 시작 시간이 "01:00:02.003" 이다. (처리 시간은 시작 시간과 끝나는 시간을 포함하므로)  
2번 로그는 끝나는 시간이 "01:00:07.000", 시작 시간이 "01:00:05.001" 이다.

그렇다면 이제 모든 로그의 이벤트 시간이 담길 `time` 리스트에 이를 로그 아이디와 함께 담는다. (끝나는 시간은 +1초를 하여 담아준다. 이유는 추후 설명)
`[(01:00:02.003, 1), (01:00:05.002, 1), (01:00:05.001, 2), (01:00:08.000, 2)]`

이제 `time` 리스트를 정렬한다.
`[(01:00:02.003, 1), (01:00:05.001, 2), (01:00:05.002, 1), (01:00:08.000, 2)]`

이제 `time` 리스트를 순회하면서 알고리즘의 4번 과정을 수행한다.

처음 가져온 값인 `(01:00:02.003, 1)`의 로그 아이디 `1`은 현재 처리 중인 로그가 담긴 집합 traffic에 존재하지 않는다.  
따라서 traffic에 로그 아이디 1을 추가한다.  
`traffic = {1}`

다음 값인 `(01:00:05.001, 2)`의 로그 아이디 `2`는 집합 traffic에 존재하지 않는다.  
따라서 traffic에 로그 아이디 2를 추가한다.  
`traffic = {1, 2}`

다음 값인 `(01:00:05.002, 1)`의 로그 아이디 `1`은 집합 traffic에 존재한다.  
따라서 traffic에서 로그 아이디 1을 제거한다.
`traffic = {2}`

마지막 값인 `(01:00:08.000, 2)`의 로그 아이디 `2`는 집합 traffic에 존재한다.  
따라서 traffic에서 로그 아이디 2을 제거한다.
`traffic = {}`

위와 같이 현재 처리 중인 로그가 담긴 집합 traffic은 `{}, {1}, {1, 2}, {2}, {}`와 같이 변한다. 이 중에서 `{1, 2}`일 때 초당 처리 중인 로그가 제일 많을 때(2개)이므로 답은 2가 된다.

그러면 위에서 끝나는 시간은 +1초를 해준 이유는 무엇일까. 이는 본 문제가 해당 순간(시간)에 겹치는 것의 개수를 세는 문제가 아니라 초(1초)당 처리량을 구하는 문제이기 때문이다.
즉, 위의 예에서 1번 로그는 `01:00:04.002`에 끝나고 2번 로그는 `01:00:05.001`에 시작하기 때문에 같은 시간에 처리 중인 것은 아니지만 `01:00:04.002 ~ 01:00:05.001`는 1초이므로 1초간 2개를 
처리한다는 것을 체크할 수 있도록 하기 위해서이다.

사실 위와 같은 방법으로 겹치는 것을 판단할 때에는 위와 같이 초당 처리 량이 아니라 해당 순간(시간)에 겹치는 것의 개수를 묻더라도 시작 시간과 끝나는 시간을 포함한다면 끝나는 시간에 
결과에 영향을 미치지 않을 작은 단위를 더해주어야 한다.

만약 최소 단위를 더해주지 않는다면 어떻게 될까. 
예를 들어서 A가 2초에 끝나고 B가 2초에 시작한다고 하자. 이 경우 A가 끝나는 시간과 B가 시작하는 시간만 봤을 때 `time` 리스트는 `[..., (2, A), (2, B), ...]` 이다.  
따라서 `traffic = {A}`인 상태에서 `(2, A)` 차례일 때 `traffic = {}`, `(2, B)` 차례일 때 `traffic = {B}`가 된다. 즉, 같은 2초에 수행 중이더라도 동시에 진행 중이라고 판단이 되지 않는다.  

그렇기 때문에 이를 처리하기 위해서 끝나는 시간에 작은 단위를 더해준다. 0.1초를 더해준다고 하면 `[..., (2, B), (2.1, A), ...]`가 되어 정상적인 결과를 얻을 수 있을 것이다.  
만약 해당 순간(시간)에 겹치는 것의 개수를 본 문제에서 물었다면 +1초가 아니라 0.0001초만 더해주면 될 것이다.

결론적으로 이러한 알고리즘을 이용한다면 모든 초에 대해서 반복문을 돌면서 모든 로그를 확인하지 않고도 nlogn의 시간 복잡도로 문제를 해결할 수 있다.
